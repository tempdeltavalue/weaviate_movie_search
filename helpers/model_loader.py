# ==============================================================================
# helpers/model_loader.py
# This script handles the loading of the embedding model, vector creation,
# and movie title generation using the Gemini API.
# ==============================================================================
import sys
import os 
import json
import torch
import requests
import traceback

from sentence_transformers import SentenceTransformer
from dataclasses import dataclass, field
from typing import List, Dict

# ==============================================================================
# Global Model and API Configuration
# ==============================================================================
# The embedding model for semantic search
MODEL_NAME = "sentence-transformers/all-MiniLM-L6-v2"
_sentence_model = None

# API configuration for the Gemini API call
API_KEY = os.getenv("API_KEY_GEMINI")
if not API_KEY:
    print("Warning: API_KEY_GEMINI environment variable is not set.", file=sys.stderr)
API_URL = "https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash-preview-05-20:generateContent?key=" + str(API_KEY)


@dataclass
class GeminiPromptConfig:
    """A data class to hold all parameters for the Gemini prompt."""
    query: str
    start_year: int = None
    end_year: int = None
    # Add other parameters here, like genre, actor, etc.

# ==============================================================================
# Functions for Text Embeddings (for Semantic Search)
# ==============================================================================
def load_embedding_model():
    """Loads the sentence-transformer model once."""
    global _sentence_model
    if _sentence_model is None:
        print(f"Loading embedding model: {MODEL_NAME}...")
        try:
            device = "cpu"
            _sentence_model = SentenceTransformer(MODEL_NAME, device=device)
            print("Embedding model loaded successfully.")
            print(f"Model is running on device: {device}")
        except Exception as e:
            print(f"Failed to load embedding model: {e}", file=sys.stderr)
            _sentence_model = None
    return _sentence_model

def get_text_embedding(text: str) -> List[float]:
    """Generates an embedding for a single text using the loaded model."""
    model = load_embedding_model()
    if model:
        try:
            embedding = model.encode(text, convert_to_tensor=True)
            return embedding.tolist()
        except Exception as e:
            print(f"Error encoding text: {e}", file=sys.stderr)
            return None
    print("Could not generate embedding due to missing model.", file=sys.stderr)
    return None

def get_text_embeddings_batch(texts: List[str]) -> List[List[float]]:
    """Generates a batch of embeddings for a list of strings."""
    model = load_embedding_model()
    if model:
        try:
            embeddings = model.encode(texts, convert_to_tensor=True)
            return embeddings.tolist()
        except Exception as e:
            print(f"Error encoding batch texts: {e}", file=sys.stderr)
            return []
    print("Could not generate embeddings due to missing model.", file=sys.stderr)
    return []

# ==============================================================================
# Functions for Query Generation using Gemini API
# ==============================================================================
def get_movie_titles_from_gemini(prompt_config: GeminiPromptConfig) -> List[str]:
    """
    Generates a list of movie titles based on a prompt configuration.
    
    Args:
        prompt_config (GeminiPromptConfig): An object containing all prompt parameters.

    Returns:
        list[str]: A list of movie titles generated by the API.
    """
    try:
        year_prompt = ""
        if prompt_config.start_year and prompt_config.end_year:
            year_prompt = f" from {prompt_config.start_year} to {prompt_config.end_year}"
        elif prompt_config.start_year:
            year_prompt = f" from {prompt_config.start_year} or later"
        elif prompt_config.end_year:
            year_prompt = f" from {prompt_config.end_year} or earlier"
            
        full_prompt = (
            f"Based on the following description, provide a list of 10 movie titles that match. "
            f"The movies should be{year_prompt}. "
            f"Only include the titles in your response."
            f"Do not include any other text or formatting besides a list of JSON objects.\n\nDescription: {prompt_config.query}"
        )
        
        payload = {
            "contents": [{
                "parts": [{ "text": full_prompt }]
            }],
            "generationConfig": {
                "responseMimeType": "application/json",
                "responseSchema": {
                    "type": "ARRAY",
                    "items": {
                        "type": "OBJECT",
                        "properties": {
                            "movie_title": { "type": "STRING" }
                        }
                    }
                }
            }
        }

        print("Calling Gemini API to generate titles...")
        response = requests.post(API_URL, json=payload)
        response.raise_for_status()
        
        result = response.json()
        
        json_str = result['candidates'][0]['content']['parts'][0]['text']
        
        titles_list_of_dicts = json.loads(json_str)
        
        titles = [item['movie_title'] for item in titles_list_of_dicts]
        
        if titles:
            print("Successfully generated movie titles.")
            return titles
        else:
            print("No movie titles were generated. Returning an empty list.")
            return []
    except Exception as e:
        print(f"An error occurred during title generation: {e}", file=sys.stderr)
        traceback.print_exc()
        return []